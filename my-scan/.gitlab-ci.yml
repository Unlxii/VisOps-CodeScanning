stages:
  - maintenance # NEW: For scheduled DB updates
  - setup
  - security_audit
  - compile # NEW: Build stage for compiled languages
  - build_artifact
  - container_scan
  - release
  - cleanup

workflow:
  name: "Scan: $PROJECT_NAME (Tag: $USER_TAG) by $GIT_USERNAME"
  rules:
    - if: $CI_PIPELINE_SOURCE == "api"
    - if: $CI_PIPELINE_SOURCE == "pipeline"
    - if: $CI_PIPELINE_SOURCE == "web"

variables:
  # Tool Versions
  GITLEAKS_VERSION: "v8.18.4"
  SEMGREP_VERSION: "latest"
  TRIVY_VERSION: "0.53.0"
  KANIKO_VERSION: "v1.23.1-debug"
  CRANE_VERSION: "debug"
  MAVEN_VERSION: "3.9-eclipse-temurin-21"
  GRADLE_VERSION: "8-jdk21"
  NODE_VERSION: "20-alpine"
  GO_VERSION: "1.22-alpine"
  PYTHON_VERSION: "3.12-alpine"

  # Project Settings
  PROJECT_NAME: "${PROJECT_NAME:-scanned-project}"
  USER_TAG: "${USER_TAG:-latest}"
  IMAGE_NAME: "docker.io/$DOCKER_USER/$PROJECT_NAME"
  TEMP_IMAGE_TAG: "temp-$CI_PIPELINE_ID"

  # Backend Configuration
  # Set ENABLE_WEBHOOKS=false for local development (backend on PC)
  # Set ENABLE_WEBHOOKS=true for production (backend on VM)
  ENABLE_WEBHOOKS: "${ENABLE_WEBHOOKS:-true}"
  WEBHOOK_TIMEOUT: "5" # Timeout in seconds for health check

  # Security Scanning Configuration
  # TRIVY_SCAN_MODE options (set by user via web app):
  #   - "fast" (default): OS packages only, 10min timeout - Quick scan for common vulnerabilities
  #   - "full": OS + Language packages (Java/Node/Python), 30min timeout - Comprehensive scan (requires good internet)
  TRIVY_SCAN_MODE: "${TRIVY_SCAN_MODE:-fast}"

  # Cache & Performance
  TRIVY_CACHE_DIR: ".trivycache/"
  TRIVY_NO_PROGRESS: "true"
  MAVEN_OPTS: "-Dmaven.repo.local=.m2/repository"
  GRADLE_USER_HOME: ".gradle"

# ==================================================
# 0. Nightly Maintenance - Update Trivy DB
# ==================================================
# Schedule this job to run at 3 AM daily:
# GitLab > CI/CD > Schedules > New Schedule
# Cron: "0 3 * * *" (3 AM every day)
# Description: "Nightly Trivy DB Update"
update_trivy_db:
  stage: maintenance
  image:
    name: aquasec/trivy:$TRIVY_VERSION
    entrypoint: [""]
  rules:
    # Run on schedule (configured in GitLab UI)
    - if: $CI_PIPELINE_SOURCE == "schedule"
    # Allow manual trigger for testing
    - if: $CI_PIPELINE_SOURCE == "web"
      when: manual
      allow_failure: true
  cache:
    key: trivy-global-cache
    paths:
      - .trivycache/
    policy: pull-push
  script:
    - echo "ðŸŒ™ Nightly Trivy DB Update Job"
    - echo "========================================"
    - echo "Updating vulnerability database..."

    # Check current DB status
    - |
      if [ -f ".trivycache/db/metadata.json" ]; then
        DB_AGE=$(( $(date +%s) - $(stat -c %Y .trivycache/db/metadata.json 2>/dev/null || echo 0) ))
        echo " Current cache age: $(($DB_AGE / 3600))h"
      else
        echo " No existing cache"
      fi

    # Download full DB (this will be incremental if cache exists)
    - |
      trivy image --download-db-only --cache-dir .trivycache/ && {
        echo " DB update completed successfully"
        NEW_DB_AGE=$(( $(date +%s) - $(stat -c %Y .trivycache/db/metadata.json 2>/dev/null || echo 0) ))
        echo " New cache age: $(($NEW_DB_AGE / 60)) minutes"
        echo "ðŸ“Š Cache will be valid for 24 hours"
      } || {
        echo "  DB update failed"
        exit 1
      }

    - echo "========================================"
    - echo "Next scheduled update Tomorrow 3 AM"
    - echo "Users can now scan without DB download!"
  artifacts:
    paths:
      - .trivycache/
    expire_in: 2 days

# ==================================================
# 1. Fetch Source (Minified for Build)
# ==================================================
fetch_source_minified:
  stage: setup
  image:
    name: alpine/git:2.45.2
    entrypoint: [""]
  retry: 2
  script:
    - echo "Pipeline Started..."

    - if ! command -v wget &> /dev/null; then apk add --no-cache wget; fi

    # Smart Webhook Function - Auto-detect backend availability
    - |
      send_webhook() {
        local payload="$1"
        local output_file="${2:-webhook_payload.json}"
        
        # Save payload to artifact (for offline mode)
        echo "$payload" > "$output_file"
        
        # Check if webhooks are enabled
        if [ "$ENABLE_WEBHOOKS" != "true" ]; then
          echo "ï¸  Webhooks disabled - Payload saved to $output_file"
          return 0
        fi
        
        # Test backend connectivity
        if wget --timeout=$WEBHOOK_TIMEOUT --spider "$BACKEND_HOST_URL/api/webhook" 2>&1 | grep -q "200\|302\|404"; then
          echo "âœ“ Backend accessible - Sending webhook..."
          wget --header="Content-Type: application/json" \
               --post-data="$payload" \
               --timeout=$WEBHOOK_TIMEOUT \
               "$BACKEND_HOST_URL/api/webhook" -O - || echo "  Webhook request failed"
        else
          echo "âœ— Backend unreachable (offline mode) - Payload saved to $output_file"
        fi
      }

    - echo "Checking Backend Connectivity - $BACKEND_HOST_URL/api/webhook"
    - |
      send_webhook "{\"pipelineId\": \"$CI_PIPELINE_ID\", \"status\": \"RUNNING\"}" "pipeline_start.json"

    - echo "Initializing Git logic..."
    - if [ -z "$USER_REPO_URL" ]; then echo "USER_REPO_URL is missing"; exit 1; fi

    - |
      if [ -n "$GIT_USERNAME" ] && [ -n "$GIT_TOKEN" ]; then
        echo "Private Repo detected..."
        CLEAN_URL=$(echo "$USER_REPO_URL" | sed -e 's|^https://||' -e 's|^http://||')
        git clone --depth 1 "https://${GIT_USERNAME}:${GIT_TOKEN}@${CLEAN_URL}" project_temp
      else
        echo "Public Repo detected..."
        git clone --depth 1 "$USER_REPO_URL" project_temp
      fi

    # Move files and cleanup
    - rm -rf project_temp/.git
    - cp -a project_temp/. .
    - rm -rf project_temp

    # Detect stack and save to file for later stages
    # IMPORTANT: Check compiled languages first (Java, Go, Rust) before interpreted ones (Node, Python)
    # This prevents false detection when projects have multiple config files
    - |
      STACK="unknown"

      # Priority 1: Compiled languages that need build stage
      if [ -f "pom.xml" ]; then 
        STACK="java-maven"
      elif [ -f "build.gradle" ] || [ -f "build.gradle.kts" ]; then 
        STACK="java-gradle"
      elif [ -f "go.mod" ]; then 
        STACK="go"
      elif [ -f "Cargo.toml" ]; then 
        STACK="rust"

      # Priority 2: Interpreted languages
      elif [ -f "package.json" ]; then 
        STACK="node"
      elif [ -f "requirements.txt" ] || [ -f "Pipfile" ] || [ -f "pyproject.toml" ]; then 
        STACK="python"
      fi

      echo "$STACK" > .detected_stack
      echo "Detected Stack: $STACK"

    - echo "Code cloned successfully."
    - ls -la

  artifacts:
    name: "source-code-$CI_PIPELINE_ID"
    paths:
      - "."
      - "*.json" # Include webhook payloads
    exclude:
      - ".git/**/*"
      - "node_modules/**/*"
      - ".m2/**/*"
      - ".gradle/**/*"
    expire_in: 1 hour

# ==================================================
# 2. Security Audits (Parallel)
# ==================================================

# Gitleaks: Clone fresh to get full history for author detection
gitleaks_scan:
  stage: security_audit
  image:
    name: zricethezav/gitleaks:$GITLEAKS_VERSION
    entrypoint: [""]
  variables:
    GIT_STRATEGY: none
  needs: []
  script:
    - echo "Gitleaks Scanning (Full History Mode)..."
    - apk add --no-cache git jq curl
    - rm -rf * .git 2>/dev/null || true

    - |
      if [ -n "$GIT_USERNAME" ] && [ -n "$GIT_TOKEN" ]; then
        CLEAN_URL=$(echo "$USER_REPO_URL" | sed -e 's|^https://||' -e 's|^http://||')
        git clone "https://${GIT_USERNAME}:${GIT_TOKEN}@${CLEAN_URL}" .
      else
        git clone "$USER_REPO_URL" .
      fi

    - gitleaks detect --source . -v --report-path gitleaks-report.json --exit-code 0

    - |
      send_webhook_smart() {
        local payload="$1"
        local output_file="${2:-webhook_payload.json}"
        echo "$payload" > "$output_file"
        
        if [ "$ENABLE_WEBHOOKS" = "true" ]; then
          wget --timeout=$WEBHOOK_TIMEOUT --spider "$BACKEND_HOST_URL/api/webhook" 2>&1 | grep -q "200\|302\|404" && {
            curl -X POST -H "Content-Type: application/json" -d "$payload" "$BACKEND_HOST_URL/api/webhook" || echo "  Webhook failed"
          } || echo "âœ— Backend unreachable - Saved to $output_file"
        else
          echo "ï¸  Webhooks disabled - Saved to $output_file"
        fi
      }
    - |
      if [ -f gitleaks-report.json ]; then
        echo "Parsing Gitleaks results with Author info..."
        
        FINDINGS=$(jq '[.[] | {
            id: .RuleID, 
            severity: "critical", 
            title: ("Secret Found: " + .Description + " by " + .Author), 
            pkgName: .File, 
            sourceTool: "Gitleaks",
            author: .Author,      
            email: .Email,
            commit: .Commit,
            message: .Message
        }]' gitleaks-report.json)
        
        PAYLOAD="{\"pipelineId\": \"$CI_PIPELINE_ID\", \"status\": \"RUNNING\", \"details\": {\"findings\": $FINDINGS}}"
        send_webhook_smart "$PAYLOAD" "gitleaks_findings.json"
      fi
  allow_failure: true
  artifacts:
    paths:
      - gitleaks-report.json
      - "*_findings.json" # Webhook payloads
    when: always

# Semgrep: Can use artifact (files only)
semgrep_scan:
  stage: security_audit
  image:
    name: returntocorp/semgrep:$SEMGREP_VERSION
    entrypoint: [""]
  needs: ["fetch_source_minified"]
  script:
    - echo "Semgrep Scanning..."
    - apk add --no-cache jq curl || true

    - semgrep scan --config=p/ci --json --output=semgrep-report.json --metrics=off . || true

    - |
      send_webhook_smart() {
        local payload="$1"
        local output_file="${2:-webhook_payload.json}"
        echo "$payload" > "$output_file"
        
        if [ "$ENABLE_WEBHOOKS" = "true" ]; then
          wget --timeout=$WEBHOOK_TIMEOUT --spider "$BACKEND_HOST_URL/api/webhook" 2>&1 | grep -q "200\|302\|404" && {
            curl -X POST -H "Content-Type: application/json" -d "$payload" "$BACKEND_HOST_URL/api/webhook" || echo "  Webhook failed"
          } || echo "âœ— Backend unreachable - Saved to $output_file"
        else
          echo "ï¸  Webhooks disabled - Saved to $output_file"
        fi
      }
    - |
      if [ -f semgrep-report.json ]; then
        echo "Parsing Semgrep results..."
        FINDINGS=$(jq '[.results[] | {id: .check_id, severity: (if .extra.severity == "ERROR" then "high" else "medium" end), title: .extra.message, pkgName: .path, sourceTool: "Semgrep"}]' semgrep-report.json)
        
        PAYLOAD="{\"pipelineId\": \"$CI_PIPELINE_ID\", \"status\": \"RUNNING\", \"details\": {\"findings\": $FINDINGS}}"
        send_webhook_smart "$PAYLOAD" "semgrep_findings.json"
      fi
  allow_failure: true
  artifacts:
    paths:
      - semgrep-report.json
      - "*_findings.json" # Webhook payloads
    when: always

# ==================================================
# 3. Compile Stage (For Java, Go, etc.)
# ==================================================

# Java Maven Build
compile_java_maven:
  stage: compile
  image: maven:$MAVEN_VERSION
  needs: ["fetch_source_minified"]
  rules:
    - if: $FORCE_STACK == "java-maven"
    - exists:
        - pom.xml
  cache:
    key: maven-$CI_PROJECT_ID
    paths:
      - .m2/repository
    policy: pull-push
  script:
    - echo "Building Java Maven project..."
    - export CONTEXT_PATH="${BUILD_CONTEXT:-.}"
    - cd "$CONTEXT_PATH"

    # Skip tests for faster build (security scan is separate)
    - mvn clean package -DskipTests -B -q

    - echo "Build completed. Checking for JAR files..."
    - find . -name "*.jar" -type f | head -20

    # Save the main JAR path for Dockerfile
    - |
      JAR_FILE=$(find target -name "*.jar" -not -name "*-sources.jar" -not -name "*-javadoc.jar" -type f | head -1)
      if [ -z "$JAR_FILE" ]; then
        echo "ERROR: No JAR file found after build!"
        exit 1
      fi
      echo "Main JAR: $JAR_FILE"
      echo "$JAR_FILE" > .jar_path
  artifacts:
    name: "compiled-java-$CI_PIPELINE_ID"
    paths:
      - "." # Pass through EVERYTHING including source files
    exclude:
      - ".git/**/*"
      - "**/target/test-classes/**"
      - "**/target/surefire-reports/**"
      - "node_modules/**/*"
      - ".m2/**/*"
      - ".gradle/**/*"
    expire_in: 1 hour

# Java Gradle Build
compile_java_gradle:
  stage: compile
  image: gradle:$GRADLE_VERSION
  needs: ["fetch_source_minified"]
  rules:
    - if: $FORCE_STACK == "java-gradle"
    - exists:
        - build.gradle
    - exists:
        - build.gradle.kts
  cache:
    key: gradle-$CI_PROJECT_ID
    paths:
      - .gradle/
    policy: pull-push
  script:
    - echo "Building Java Gradle project..."
    - export CONTEXT_PATH="${BUILD_CONTEXT:-.}"
    - cd "$CONTEXT_PATH"

    - gradle clean build -x test --no-daemon -q

    - echo "Build completed. Checking for JAR files..."
    - find . -name "*.jar" -type f | head -20

    - |
      JAR_FILE=$(find build/libs -name "*.jar" -not -name "*-plain.jar" -type f | head -1)
      if [ -z "$JAR_FILE" ]; then
        JAR_FILE=$(find build/libs -name "*.jar" -type f | head -1)
      fi
      if [ -z "$JAR_FILE" ]; then
        echo "ERROR: No JAR file found after build!"
        exit 1
      fi
      echo "Main JAR: $JAR_FILE"
      echo "$JAR_FILE" > .jar_path
  artifacts:
    name: "compiled-gradle-$CI_PIPELINE_ID"
    paths:
      - "." # Pass through EVERYTHING including source files
    exclude:
      - ".git/**/*"
      - "node_modules/**/*"
      - ".m2/**/*"
      - ".gradle/**/*"
    expire_in: 1 hour

# Go Build
compile_go:
  stage: compile
  image: golang:$GO_VERSION
  needs: ["fetch_source_minified"]
  rules:
    - if: $FORCE_STACK == "go"
    - exists:
        - go.mod
  cache:
    key: go-$CI_PROJECT_ID
    paths:
      - .go/pkg/mod/
    policy: pull-push
  script:
    - echo "Building Go project..."
    - export CONTEXT_PATH="${BUILD_CONTEXT:-.}"
    - export GOPATH="$CI_PROJECT_DIR/.go"
    - cd "$CONTEXT_PATH"

    - go mod download
    - CGO_ENABLED=0 GOOS=linux go build -o app .

    - echo "Build completed."
    - ls -la app
  artifacts:
    name: "go-app-build"
    paths:
      - "." # Pass through EVERYTHING including source files
    exclude:
      - ".git/**/*"
      - ".go/**/*"
      - "**/app"
      - ".detected_stack"
    expire_in: 1 hour

# Node.js - Just install dependencies (no compile needed for most)
compile_node:
  stage: compile
  image: node:$NODE_VERSION
  needs: ["fetch_source_minified"]
  rules:
    - if: $FORCE_STACK == "node"
    - exists:
        - package.json
  cache:
    key: node-$CI_PROJECT_ID
    paths:
      - node_modules/
    policy: pull-push
  script:
    - echo "Installing Node.js dependencies..."
    - export CONTEXT_PATH="${BUILD_CONTEXT:-.}"
    - cd "$CONTEXT_PATH"

    - |
      if [ -f "package-lock.json" ]; then
        npm ci --silent
      elif [ -f "yarn.lock" ]; then
        yarn install --frozen-lockfile --silent
      else
        npm install --silent
      fi

    # Build if there's a build script
    - |
      if grep -q '"build"' package.json; then
        echo "Running build script..."
        npm run build || true
      fi

    - echo "Node.js setup completed."
  artifacts:
    name: "compiled-node-$CI_PIPELINE_ID"
    paths:
      - "."
    exclude:
      - ".git/**/*"
    expire_in: 1 hour

# Python - No compile needed, just pass through
compile_python:
  stage: compile
  image: python:$PYTHON_VERSION
  needs: ["fetch_source_minified"]
  rules:
    - if: $FORCE_STACK == "python"
    - exists:
        - requirements.txt
    - exists:
        - Pipfile
    - exists:
        - pyproject.toml
  script:
    - echo "Python project detected - no compilation needed"
    - echo "python" > .detected_stack
  artifacts:
    name: "source-python-$CI_PIPELINE_ID"
    paths:
      - "."
    exclude:
      - ".git/**/*"
    expire_in: 1 hour

# ==================================================
# 4. Build Docker Image (Kaniko)
# ==================================================
build_and_push:
  stage: build_artifact
  image:
    name: gcr.io/kaniko-project/executor:$KANIKO_VERSION
    entrypoint: [""]
  needs:
    - job: fetch_source_minified
      optional: false
      artifacts: true
    - job: compile_java_maven
      optional: true
      artifacts: true # à¸”à¸¶à¸‡ artifacts à¸–à¹‰à¸² job à¸—à¸³à¸‡à¸²à¸™
    - job: compile_java_gradle
      optional: true
      artifacts: true
    - job: compile_go
      optional: true
      artifacts: true
    - job: compile_node
      optional: true
      artifacts: true
    - job: compile_python
      optional: true
      artifacts: true
  script:
    - echo "Starting Docker Build..."
    - if [ -z "$DOCKER_USER" ]; then echo "No Docker Creds"; exit 1; fi

    - export IMAGE_NAME="docker.io/$DOCKER_USER/$PROJECT_NAME"
    - export CONTEXT_PATH="${BUILD_CONTEXT:-.}"

    # Read detected stack
    - |
      STACK="unknown"
      if [ -f ".detected_stack" ]; then
        STACK=$(cat .detected_stack)
      fi
      echo "Using Stack: $STACK"

    # Check for Dockerfile and determine build strategy
    # Priority: manual > smart-detection > generate
    - |
      DOCKERFILE_STRATEGY="unknown"

      if [ -f "Dockerfile.manual" ]; then
        echo "Strategy: USER_MANUAL - Using user-provided Dockerfile.manual"
        mkdir -p "$CONTEXT_PATH"
        cp Dockerfile.manual "$CONTEXT_PATH/Dockerfile"
        DOCKERFILE_STRATEGY="manual"
        
      elif [ -f "$CONTEXT_PATH/Dockerfile" ] || [ -f "Dockerfile" ]; then
        # Found existing Dockerfile - check if it's compatible with pre-compiled artifacts
        EXISTING_DF="Dockerfile"
        [ -f "$CONTEXT_PATH/Dockerfile" ] && EXISTING_DF="$CONTEXT_PATH/Dockerfile"
        
        echo "Found existing Dockerfile at: $EXISTING_DF"
        
        # Analyze Dockerfile compatibility
        needs_override=false
        
        # Case 1: Dockerfile does its own compilation (has build tools)
        if grep -qE '(FROM.*(maven|gradle|openjdk.*jdk)|RUN.*(mvn|gradle))' "$EXISTING_DF"; then
          echo "    Contains build stage with Maven/Gradle"
          needs_override=true
        fi
        
        # Case 2: Dockerfile expects specific artifact filenames (not wildcards)
        # Good: COPY target/*.jar app.jar
        # Bad:  COPY target/myapp-1.0.0-SNAPSHOT.jar app.jar
        if grep -E 'COPY.*\.(jar|war)' "$EXISTING_DF" | grep -vE '\*\.(jar|war)' | grep -qE '(target|build/libs)'; then
          echo "    COPY specific artifact filename (not wildcard)"
          needs_override=true
        fi
        
        # Case 3: Multi-stage build that copies from builder
        if grep -qE 'COPY --from=.*(target|build)' "$EXISTING_DF"; then
          echo "    Multi-stage build copying from builder stage"
          needs_override=true
        fi
        
        if [ "$needs_override" = "true" ]; then
          echo "  Strategy: OVERRIDE - Fetching compatible template from API"
          
          # Fetch optimized template from backend API
          wget --header="x-api-key: $API_KEY" -O "$CONTEXT_PATH/Dockerfile" \
            "$BACKEND_HOST_URL/api/templates?stack=$STACK" || {
              echo "  Failed to fetch template from API, using fallback"
              
              if [ "$STACK" = "java-maven" ] || [ "$STACK" = "java-gradle" ]; then
                # Fallback: Generate simple Dockerfile for Java
                echo "FROM eclipse-temurin:21-jre-alpine" > "$CONTEXT_PATH/Dockerfile"
                echo "WORKDIR /app" >> "$CONTEXT_PATH/Dockerfile"
                echo "COPY target/*.jar app.jar" >> "$CONTEXT_PATH/Dockerfile"
                echo "EXPOSE 8080" >> "$CONTEXT_PATH/Dockerfile"
                echo 'ENTRYPOINT ["java", "-jar", "app.jar"]' >> "$CONTEXT_PATH/Dockerfile"
              else
                echo "FROM alpine:latest" > "$CONTEXT_PATH/Dockerfile"
                echo "WORKDIR /app" >> "$CONTEXT_PATH/Dockerfile"
                echo "COPY . ." >> "$CONTEXT_PATH/Dockerfile"
                echo 'CMD ["/bin/sh"]' >> "$CONTEXT_PATH/Dockerfile"
              fi
            }
          DOCKERFILE_STRATEGY="generated"
        else
          # Dockerfile is compatible - use as-is
          echo "   Strategy: USE_EXISTING - Dockerfile compatible with pre-compiled artifacts"
          if [ "$CONTEXT_PATH" != "." ] && [ -f "Dockerfile" ]; then
            cp Dockerfile "$CONTEXT_PATH/Dockerfile"
          fi
          DOCKERFILE_STRATEGY="existing"
        fi
        
      else
        # No Dockerfile found - generate one from API
        echo "Strategy: GENERATE - No Dockerfile found, fetching template from API"
        mkdir -p "$CONTEXT_PATH"
        
        # Fetch template from backend API (primary method)
        wget --header="x-api-key: $API_KEY" -O "$CONTEXT_PATH/Dockerfile" \
          "$BACKEND_HOST_URL/api/templates?stack=$STACK" || {
            echo "Failed to fetch template from API, using fallback"
            
            # Fallback: Generate basic Dockerfile based on stack
            if [ "$STACK" = "java-maven" ] || [ "$STACK" = "java-gradle" ]; then
              echo "FROM eclipse-temurin:21-jre-alpine" > "$CONTEXT_PATH/Dockerfile"
              echo "WORKDIR /app" >> "$CONTEXT_PATH/Dockerfile"
              echo "COPY target/*.jar app.jar" >> "$CONTEXT_PATH/Dockerfile"
              echo "EXPOSE 8080" >> "$CONTEXT_PATH/Dockerfile"
              echo 'ENTRYPOINT ["java", "-jar", "app.jar"]' >> "$CONTEXT_PATH/Dockerfile"
            else
              echo "FROM alpine:latest" > "$CONTEXT_PATH/Dockerfile"
              echo "COPY . /app" >> "$CONTEXT_PATH/Dockerfile"
              echo "WORKDIR /app" >> "$CONTEXT_PATH/Dockerfile"
            fi
          }
        DOCKERFILE_STRATEGY="generated"
      fi

      echo "Dockerfile Strategy: $DOCKERFILE_STRATEGY"

    - echo "=== Dockerfile Contents ==="
    - cat "$CONTEXT_PATH/Dockerfile"
    - echo "==========================="

    # Debug - Show available files in context
    - echo "=== Debug - Files in Context Path ==="
    - ls -lah "$CONTEXT_PATH/" || true
    - echo "=== Looking for JAR files ==="
    - find "$CONTEXT_PATH" -name "*.jar" -type f 2>/dev/null | head -20 || echo "No JAR files found"
    - echo "=== Looking in build directories ==="
    - ls -lah "$CONTEXT_PATH/target/" 2>/dev/null || echo "No target/ directory"
    - ls -lah "$CONTEXT_PATH/build/libs/" 2>/dev/null || echo "No build/libs/ directory"
    - echo "=== Context Debug Complete ==="

    # Setup Docker auth
    - mkdir -p /kaniko/.docker
    - AUTH_STR=$(echo -n "$DOCKER_USER:$DOCKER_PASSWORD" | base64 | tr -d '\n')
    - |
      echo "{\"auths\":{\"https://index.docker.io/v1/\":{\"auth\":\"$AUTH_STR\"},\"index.docker.io\":{\"auth\":\"$AUTH_STR\"}}}" > /kaniko/.docker/config.json

    # Build with Kaniko
    - |
      /kaniko/executor \
        --context "$CI_PROJECT_DIR/$CONTEXT_PATH" \
        --dockerfile "$CI_PROJECT_DIR/$CONTEXT_PATH/Dockerfile" \
        --destination "$IMAGE_NAME:$TEMP_IMAGE_TAG" \
        --cache=true \
        --cache-ttl=24h \
        --snapshot-mode=redo \
        --use-new-run

# ==================================================
# 5. Container Scan (Trivy)
# ==================================================
trivy_scan:
  stage: container_scan
  image:
    name: aquasec/trivy:$TRIVY_VERSION
    entrypoint: [""]
  needs: ["build_and_push"]
  variables:
    TRIVY_USERNAME: "$DOCKER_USER"
    TRIVY_PASSWORD: "$DOCKER_PASSWORD"
    TRIVY_AUTH_URL: "https://index.docker.io/v1/"
  cache:
    key: trivy-global-cache
    paths:
      - .trivycache/
    policy: pull-push
  script:
    - export IMAGE_NAME="docker.io/$DOCKER_USER/$PROJECT_NAME"
    - echo "Target Image - $IMAGE_NAME:$TEMP_IMAGE_TAG"
    - apk add --no-cache curl jq

    # Configure scan mode and timeout based on user selection
    - |
      echo "========================================"
      echo "Selected Scan Mode: $TRIVY_SCAN_MODE"
      echo "========================================"

      if [ "$TRIVY_SCAN_MODE" = "full" ]; then
        echo " Full scan mode: OS + Language packages (Java/Node/Python dependencies)"
        echo "  Timeout: 30 minutes (comprehensive scan, requires good internet)"
        unset TRIVY_SKIP_JAVA_DB_UPDATE
        SKIP_FLAGS=""
        SCANNERS="--scanners vuln"
        TIMEOUT="30m"
        echo "Java DB: Will download (for language scanning)"
      else
        echo " Fast scan mode: OS packages only (skip language dependencies)"
        echo "  Timeout: 10 minutes (quick scan, recommended for most users)"
        export TRIVY_SKIP_JAVA_DB_UPDATE="true"
        SKIP_FLAGS="--skip-java-db-update"
        SCANNERS="--scanners vuln"
        TIMEOUT="10m"
        echo "Java DB: Skipped (env: $TRIVY_SKIP_JAVA_DB_UPDATE)"
      fi
      echo "========================================"

    # Incremental DB Update Strategy
    - |
      echo "Checking Trivy DB cache..."
      if [ -f ".trivycache/db/metadata.json" ]; then
        DB_AGE=$(( $(date +%s) - $(stat -c %Y .trivycache/db/metadata.json 2>/dev/null || echo 0) ))
        DB_AGE_HOURS=$(($DB_AGE / 3600))
        echo " Cache found (${DB_AGE_HOURS}h old)"
        
        if [ "$DB_AGE_HOURS" -lt 48 ]; then
          echo " Cache is fresh - Using pre-downloaded DB (Nightly Update strategy)"
          echo " DB last updated: $(date -r .trivycache/db/metadata.json 2>/dev/null || echo 'unknown')"
        else
          echo "  Cache is older than 48h - May need scheduled update"
          echo " Configure nightly update job to run at 3 AM"
        fi
      else
        echo " No cache found - First run will download DB"
        echo " After first scan, enable nightly update schedule for instant scans"
      fi

    - echo "Trivy Scanning (using cached DB)..."

    # Run scan with SKIP DB UPDATE (use pre-downloaded cache)
    - |
      trivy image \
        --timeout $TIMEOUT \
        $SCANNERS \
        --format json \
        --output trivy-report.json \
        --skip-db-update \
        $SKIP_FLAGS \
        --severity CRITICAL,HIGH,MEDIUM,LOW \
        --ignore-unfixed \
        --parallel 4 \
        --skip-files "/usr/local/**" \
        --skip-files "/opt/**" \
        "$IMAGE_NAME:$TEMP_IMAGE_TAG" || {
          echo "  Trivy scan failed or timed out after $TIMEOUT"
          echo " Tip: If timeout occurs frequently, check your internet connection"
          echo '{"Results":[]}' > trivy-report.json
        }

    - |
      send_webhook_smart() {
        local payload="$1"
        local output_file="${2:-webhook_payload.json}"
        echo "$payload" > "$output_file"
        
        if [ "$ENABLE_WEBHOOKS" = "true" ]; then
          wget --timeout=$WEBHOOK_TIMEOUT --spider "$BACKEND_HOST_URL/api/webhook" 2>&1 | grep -q "200\|302\|404" && {
            curl -X POST -H "Content-Type: application/json" -d "$payload" "$BACKEND_HOST_URL/api/webhook" || echo "  Webhook failed"
          } || echo "âœ— Backend unreachable - Saved to $output_file"
        else
          echo "Webhooks disabled - Saved to $output_file"
        fi
      }
    - |
      if [ -f trivy-report.json ]; then
        echo "Parsing Trivy results..."
        FINDINGS=$(jq '[.Results[]?.Vulnerabilities[]? | {id: .VulnerabilityID, severity: (.Severity | ascii_downcase), title: .Title, pkgName: .PkgName, installedVersion: .InstalledVersion, fixedVersion: .FixedVersion, sourceTool: "Trivy"}]' trivy-report.json)
        
        if [ -z "$FINDINGS" ] || [ "$FINDINGS" == "null" ]; then FINDINGS="[]"; fi

        PAYLOAD="{\"pipelineId\": \"$CI_PIPELINE_ID\", \"status\": \"RUNNING\", \"details\": {\"findings\": $FINDINGS}}"
        send_webhook_smart "$PAYLOAD" "trivy_findings.json"
      fi
  allow_failure: true
  artifacts:
    paths:
      - trivy-report.json
      - "*_findings.json" # Webhook payloads
    when: always

# ==================================================
# 6. Release (Crane)
# ==================================================
push_to_hub:
  stage: release
  image:
    name: gcr.io/go-containerregistry/crane:$CRANE_VERSION
    entrypoint: [""]
  needs: ["trivy_scan"]
  # Require manual approval before pushing to production
  when: manual
  allow_failure: false
  script:
    - export IMAGE_NAME="docker.io/$DOCKER_USER/$PROJECT_NAME"
    - echo "Checking security scan results..."

    # Use grep instead of jq (crane image doesn't have package manager)
    - CRITICAL_COUNT=0
    - |
      if [ -f trivy-report.json ]; then
        # Count CRITICAL vulnerabilities using grep (handle empty results)
        CRITICAL_COUNT=$(grep -o '"Severity":"CRITICAL"' trivy-report.json 2>/dev/null | wc -l || echo "0")
        CRITICAL_COUNT=${CRITICAL_COUNT:-0}
        
        echo "========================================"
        echo "Security Scan Results:"
        echo "  CRITICAL Vulnerabilities: $CRITICAL_COUNT"
        echo "========================================"
        
        if [ "$CRITICAL_COUNT" -gt 0 ]; then
          echo ""
          echo "CRITICAL Vulnerabilities Found:"
          echo "========================================"
          
          # Display sample vulnerabilities (simplified, with error handling)
          {
            grep -B 5 -A 10 '"Severity":"CRITICAL"' trivy-report.json 2>/dev/null | head -100 | \
              grep -E '"VulnerabilityID"|"PkgName"|"InstalledVersion"|"FixedVersion"' 2>/dev/null | \
              sed 's/.*"VulnerabilityID":"\([^"]*\)".*/  â€¢ \1/g' 2>/dev/null | \
              sed 's/.*"PkgName":"\([^"]*\)".*/    Package: \1/g' 2>/dev/null | \
              sed 's/.*"InstalledVersion":"\([^"]*\)".*/    Version: \1/g' 2>/dev/null | \
              sed 's/.*"FixedVersion":"\([^"]*\)".*/    Fix: \1\n/g' 2>/dev/null
          } || echo "  (Unable to parse vulnerability details)"
          
          if [ "$CRITICAL_COUNT" -gt 5 ]; then
            echo "  ... and more (total: $CRITICAL_COUNT issues)"
          fi
          echo "========================================"
        fi
      else
        echo "No trivy-report.json found, assuming no scan results"
        CRITICAL_COUNT=0
      fi

    - |
      if [ "$CRITICAL_COUNT" -gt 0 ]; then
         echo ""
         echo " RELEASE BLOCKED - MANUAL INTERVENTION REQUIRED"
         echo "========================================"
         echo "Found $CRITICAL_COUNT CRITICAL vulnerabilities"
         echo " Cannot proceed with deployment"
         echo " Action required:"
         echo "   1. Review vulnerabilities above"
         echo "   2. Fix critical issues in source code"
         echo "   3. Re-run the scan pipeline"
         echo "========================================"
         echo "  This job will automatically FAIL"
         echo "  Temporary image will be deleted for security"
         echo "========================================"
         
         # Create simple JSON payload (without jq)
         PAYLOAD="{\"pipelineId\": \"$CI_PIPELINE_ID\", \"status\": \"BLOCKED\", \"vulnCritical\": $CRITICAL_COUNT}"
         echo "$PAYLOAD" > release_blocked.json
         
         if [ "$ENABLE_WEBHOOKS" = "true" ]; then
           wget --timeout=$WEBHOOK_TIMEOUT --spider "$BACKEND_HOST_URL/api/webhook" 2>&1 | grep -q "200\|302\|404" && {
             wget --header="Content-Type: application/json" --post-data="$PAYLOAD" "$BACKEND_HOST_URL/api/webhook" -O - || echo "  Webhook failed"
           } || echo "âœ— Backend unreachable - Saved to release_blocked.json"
         else
           echo "Webhooks disabled - Saved to release_blocked.json"
         fi
         exit 1
      fi

      echo ""
      echo " SECURITY CHECK PASSED - READY FOR REVIEW"
      echo "========================================"
      echo " No CRITICAL vulnerabilities found"
      echo " Manual approval required before deployment"
      echo ""
      echo "Please review:"
      echo "  â€¢ Scan results above"
      echo "  â€¢ Image tag: $USER_TAG"
      echo "  â€¢ Target: $IMAGE_NAME"
      echo ""
      echo "If approved, this job will:"
      echo "  1. Promote temp image to final tag"
      echo "  2. Push to Docker Hub: $IMAGE_NAME:$USER_TAG"
      echo "  3. Delete temporary image"
      echo "========================================"
      echo " Waiting for manual approval..."
      echo ""

      crane auth login -u "$DOCKER_USER" -p "$DOCKER_PASSWORD" index.docker.io
      crane cp "$IMAGE_NAME:$TEMP_IMAGE_TAG" "$IMAGE_NAME:$USER_TAG"
      crane delete "$IMAGE_NAME:$TEMP_IMAGE_TAG" || true

      echo ""
      echo " DEPLOYMENT SUCCESSFUL"
      echo "========================================"
      echo "Image promoted: $IMAGE_NAME:$USER_TAG"
      echo "Temporary image cleaned up"
      echo "========================================"

      PAYLOAD="{\"pipelineId\": \"$CI_PIPELINE_ID\", \"status\": \"SUCCESS\"}"
      echo "$PAYLOAD" > release_success.json

      if [ "$ENABLE_WEBHOOKS" = "true" ]; then
        wget --timeout=$WEBHOOK_TIMEOUT --spider "$BACKEND_HOST_URL/api/webhook" 2>&1 | grep -q "200\|302\|404" && {
          wget --header="Content-Type: application/json" --post-data="$PAYLOAD" "$BACKEND_HOST_URL/api/webhook" -O - || echo "  Webhook failed"
        } || echo "âœ— Backend unreachable - Saved to release_success.json"
      else
        echo "Webhooks disabled - Saved to release_success.json"
      fi

# ==================================================
# 7. Cleanup & Notification
# ==================================================
notify_failure:
  stage: cleanup
  image:
    name: curlimages/curl:latest
    entrypoint: [""]
  script:
    - echo "Pipeline Failed! Sending Webhook..."
    - |
      PAYLOAD="{\"pipelineId\": \"$CI_PIPELINE_ID\", \"status\": \"FAILED\"}"
      echo "$PAYLOAD" > pipeline_failed.json

      if [ "$ENABLE_WEBHOOKS" = "true" ]; then
        wget --timeout=$WEBHOOK_TIMEOUT --spider "$BACKEND_HOST_URL/api/webhook" 2>&1 | grep -q "200\|302\|404" && {
          curl -X POST -H "Content-Type: application/json" -d "$PAYLOAD" "$BACKEND_HOST_URL/api/webhook" || echo "  Webhook failed"
        } || echo "âœ— Backend unreachable - Saved to pipeline_failed.json"
      else
        echo "Webhooks disabled - Saved to pipeline_failed.json"
      fi
  when: on_failure
  allow_failure: true
  artifacts:
    paths:
      - "*.json"
    when: always
    expire_in: 7 days

cleanup_temp_image:
  stage: cleanup
  image:
    name: gcr.io/go-containerregistry/crane:$CRANE_VERSION
    entrypoint: [""]
  variables:
    GIT_STRATEGY: none
  script:
    - echo "Ensuring cleanup..."
    - if [ -z "$DOCKER_USER" ]; then exit 0; fi
    - export IMAGE_NAME="docker.io/$DOCKER_USER/$PROJECT_NAME"
    - crane auth login -u "$DOCKER_USER" -p "$DOCKER_PASSWORD" index.docker.io || true
    - crane delete "$IMAGE_NAME:$TEMP_IMAGE_TAG" || true
  when: always
